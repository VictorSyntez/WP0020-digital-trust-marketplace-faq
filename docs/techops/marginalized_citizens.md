## Question: How best to avoid digital identity services that marginalize segments of a population?  

There are many different ways in which people and communities may come to be excluded from digital trust ecosystems and their benefits.

Some may be excluded due to social biases and economic disadvantages while others will face different kinds of obstacles based on a disability or the location of the community where they live.  

Facing this significant challenge, and creating ecosystems that serve diverse communities that fully benefit from their adoption and success, requires that frameworks and services be conceived with these questions in mind from the start.

ToIP, for example, has recent approved the establishment of a Human Experience Working Group that will not only explore the design of applications whose use fosters trust among and between persons. It will also seek to bring the diverse voices and perspectives of people who may not currently have the means to participate in ToIP into our work.

Along with established measures (e.g. all ecosystems which use Hyperledger Indy and Aries components have a design to be used offline and asynchronously), the following other factors need to be considered in ecosystem design:

* Societal exclusion of people and communities where income inequalities, forms of educational/knowledge, among other factors, may make it difficult to adopt advanced digital applications
* Physical or cognitive impairment (e.g. due to disability or mental health condition) including age related conditions such as poor manual dexterity and dementia.
* Geographic exclusion, due to limited access to mobile or fixed line data services
* Language and literacy, (e.g. populations with low or poor literacy in local languages or those for whom French or English are not their native language).

Access to digital services should be addressed in three pillars to develop a fully usable service, and enable the identity holders to have as much self-sovereignty as possible:

1. Use of a special kind of delegation and designation called ‘Guardianship’ which allows for individuals to choose (or have chosen for them depending on the context), a person who manages their ID for them.  Guardian examples include children, those who are digitally excluded, and adults living with dementia or with a learning difficulty.  This model enables provision of a ‘digital assist’ model of service delivery with intermediaries (for example through networks of banks, post offices, or community groups). For a detailed discussion of digital guardianship, see the Sovrin Foundation Guardianship white paper.
2. Access using low-tech connectors, for example QR Codes and SMS or voice channels allowing access in low/no connectivity areas.
3. Offline connectors that bind the individual to the digital ID (e.g. biometrics, secure tokens or authoritative identity evidence)

The following issues further extend the impact to marginalized citizens beyond identity:

* Financial exclusion for those without access to a bank account or with a ‘thin’ credit file
* Social or political exclusion, for people and communities faced with persistent bias such as women, cultural minorities, indiginous peoples, and newly arrived migrants.

Including those potentially marginalized populations requires other techniques to design a service that is fit for its purpose:

1. Inclusive and respectful design models which engage early on with representatives from marginalized communities and enable them to co-create the user experiences and define from the outset their requirements
2. Designing all citizen services to be accessible at very low levels of assurance, modularizing them and promoting access to services above identification of the participant
3. Innovation in methods and evidence required for identity vetting allowing alternatives to state-issued documents, financial services and household bills.
4. Understanding of the socio-political factors at play in all of the communities served so that every effort is made to de-politicize and reduce the risk to individual’s privacy and personal safety when ‘signing up’ for, or using a digital ID.  This means that the language, design and approach for user interface and service design need to be flexible and adaptable to consider the preferences of marginalized populations.
